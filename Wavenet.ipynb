{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f57f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed4c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# reading in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(words[:8])\n",
    "#print(type(words)) # splitlines returns a list\n",
    "print(max(len(w) for w in words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177a92c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# building the vocanulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s : i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "108dd3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2dfa128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# building the dataset\n",
    "block_size = 8\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        \n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fcadda96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ ------> y\n",
      ".......y ------> u\n",
      "......yu ------> h\n",
      ".....yuh ------> e\n",
      "....yuhe ------> n\n",
      "...yuhen ------> g\n",
      "..yuheng ------> .\n",
      "........ ------> d\n",
      ".......d ------> i\n",
      "......di ------> o\n",
      ".....dio ------> n\n",
      "....dion ------> d\n",
      "...diond ------> r\n",
      "..diondr ------> e\n",
      ".diondre ------> .\n",
      "........ ------> x\n",
      ".......x ------> a\n",
      "......xa ------> v\n",
      ".....xav ------> i\n",
      "....xavi ------> e\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print(''.join(itos[ix.item()] for ix in x), '------>', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e09b7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a deeper n/w\n",
    "\n",
    "class Linear:\n",
    "    \n",
    "    def __init__(self, fan_in, fan_out, bias=True): # fan_in = input_features, similarly out\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "    \n",
    "class BatchNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1): # dim = num of features of input\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backpropagation)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training: \n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "            xmean = x.mean(dim, keepdim=True) # batch mean (instead of passing the 0th dimension alone now passed a tuple to get mean over 0th and 1st dimension as 3 dimensional tensor now)\n",
    "            xvar = x.var(dim, keepdim=True)\n",
    "        else: # while giving the single input while testing(not training)\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        \n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    \n",
    "class Embedding:\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "        \n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "    \n",
    "\n",
    "class FlattenConsecutive:\n",
    "    \n",
    "    def __init__(self, n): # n would signify how many characters to send to the next layer(2 in our case)\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze() # squeeze the first dimension ie like before will give 2 dimensional tensor\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "\n",
    "class Sequential:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        # get the params of all the layers and stretch them into one list\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "33b20dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "64887af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76579\n"
     ]
    }
   ],
   "source": [
    "n_embed = 24 # the dimension of the character embedding vectors\n",
    "n_hidden = 128\n",
    "#C = torch.randn((vocab_size, n_embed))\n",
    "\n",
    "# list of layers required in MLP\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embed),\n",
    "    FlattenConsecutive(2), Linear(n_embed * 2, n_hidden, bias = False),BatchNorm1d(n_hidden),Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias = False),BatchNorm1d(n_hidden),Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias = False),BatchNorm1d(n_hidden),Tanh(),\n",
    "    Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "\n",
    "# batch norm layer only taking mean over the 0th dimension, but tensors changed from 2 to 3 dimensions, so need to fix that.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # last layer: make less confident (as seen above)\n",
    "    # since last layer has been updated to batchnorm1d, wont be changing the last layers's weight instead the factor gamma which multiplicatively interacts with the output of that normalization\n",
    "    #layers[-1].gamma *= 0.1\n",
    "    layers[-1].weight *= 0.1\n",
    "    # all other layers apply gain\n",
    "#     for layer in layers[:-1]:\n",
    "#         if isinstance(layer, Linear):\n",
    "#             layer.weight *= 5/3 # since using tanh\n",
    "            \n",
    "#parameters = [p for layer in layers for p in layer.parameters()]\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # total parameters\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "36609e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (4, 8, 10)\n",
      "FlattenConsecutive : (4, 4, 20)\n",
      "Linear : (4, 4, 200)\n",
      "BatchNorm1d : (4, 4, 200)\n",
      "Tanh : (4, 4, 200)\n",
      "FlattenConsecutive : (4, 2, 400)\n",
      "Linear : (4, 2, 200)\n",
      "BatchNorm1d : (4, 2, 200)\n",
      "Tanh : (4, 2, 200)\n",
      "FlattenConsecutive : (4, 400)\n",
      "Linear : (4, 200)\n",
      "BatchNorm1d : (4, 200)\n",
      "Tanh : (4, 200)\n",
      "Linear : (4, 27)\n"
     ]
    }
   ],
   "source": [
    "# # running the after block once before running this block to pass the input to model to work on, previously just initialized the layers\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3fd00",
   "metadata": {},
   "source": [
    "### example how to make a wavenet like architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7c603f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  1,  2, 18,  9],\n",
       "        [ 0,  0,  0, 22,  9,  3, 20, 15],\n",
       "        [ 0,  0,  1, 14,  7,  5, 12,  5],\n",
       "        [19, 15,  3,  8,  9, 11,  1,  9]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ix = torch.randint(0, Xtr.shape[0], (4,)) # taking 4 as a batch size here each of 8 characters and each character of 10 dim\n",
    "# Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "# logits = model(Xb)\n",
    "# print(Xb.shape)\n",
    "# Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd407f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.layers[0].out.shape # model a object of sequential, has layers, each layer stores it's output in out which is accessed.\n",
    "# # embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3daa9e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.layers[1].out.shape # flatten (all 8 characters into a single row) and columns being the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bde6b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.layers[2].out.shape # linear multiplied with (80, 200) weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "499c4bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 200])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (torch.randn(4,4,20) @ torch.randn(20, 200) + torch.randn(200)).shape # here only last dimension should match, and @ can be used\n",
    "# # so this feature of '@' can be used to implement wavenet architecture where all the contexts are not fed together to next\n",
    "# # layer, instead 2 charcters are fed here\n",
    "# # so need to change the flatten layer that changes (4, 8, 10) to (4, 4, 20) and then multiplied with weight matrix.\n",
    "# # basically flatten layer creates this mini batch of 2 charcaters inside a batch for us.\n",
    "# # so does change the linear layer as well, the dim of weight matrix, how many numbers it should expect here 20.\n",
    "\n",
    "# # block_size = 8, n_embed = 10 ( 8 characters of 10 dimension each to predict the next character)\n",
    "# # need to feed only 2 character each so 2x10 and total 4 so \n",
    "# (1,2), (3,4), (5,6), (7,8) # process all of them in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc0e72d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 20])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e = torch.randn(4, 8, 10)\n",
    "# explicit = torch.cat([e[:, ::2, :], e[:, 1::2, :]], dim=2)\n",
    "# explicit.shape\n",
    "# explicit\n",
    "# # taking all the even characters and the odd characters and placing them right next to each other\n",
    "# # (0,1),(2,3),(4,5),(6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b874bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # could also be done this way using view only\n",
    "# (e.view(4,4,20) == explicit).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2876b",
   "metadata": {},
   "source": [
    "### end of the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f0e149d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  50000: 3.5936\n",
      "  10000/  50000: 2.0988\n",
      "  20000/  50000: 2.3559\n",
      "  30000/  50000: 1.8906\n",
      "  40000/  50000: 1.9149\n"
     ]
    }
   ],
   "source": [
    "max_steps =  50000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    \n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X, Y\n",
    "    \n",
    "    # forward pass\n",
    "#     x = Xb\n",
    "# #     emb = C[Xb]\n",
    "# #     x = emb.view(emb.shape[0], -1)\n",
    "#     for layer in layers:\n",
    "#         x = layer(x) # Linear was already initialized above now calling only to get Y of that layer and stored in x\n",
    "#     loss = F.cross_entropy(x, Yb) # comparing final logits and Yb\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.1 if i < 150000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # track stats\n",
    "    if i%10000 == 0:\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "709fd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3812dfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x206ecee4c70>]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting a much better loss curve\n",
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "82220cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.9709885120391846\n",
      "val 2.0740771293640137\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disabless gradient tarcking\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        'train' : {Xtr, Ytr},\n",
    "        'val' : {Xdev, Ydev},\n",
    "        'test' : {Xte, Yte},\n",
    "    }[split]\n",
    "    \n",
    "#     emb = C[x] #(N, block_size, n_embd(10))\n",
    "#     x = emb.view(emb.shape[0], -1)\n",
    "#     for layer in layers:\n",
    "#         x = layer(x)\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    \n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5359ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode(needed especially for batchnorm layer(due to mean and std))\n",
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0159aca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emadelin.\n",
      "phar.\n",
      "ketta.\n",
      "lua.\n",
      "inar.\n",
      "fenne.\n",
      "xaviana.\n",
      "danika.\n",
      "zharee.\n",
      "addin.\n",
      "mazalyna.\n",
      "makinley.\n",
      "dreyra.\n",
      "kola.\n",
      "malay.\n",
      "karrin.\n",
      "marie.\n",
      "zatalia.\n",
      "kevan.\n",
      "bogan.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # contains index of each alpha initially '...'\n",
    "    while True:\n",
    "        logits = model(torch.tensor([context]))\n",
    "#         emb = C[torch.tensor([context])] #(1, block_size, d)\n",
    "#         x = emb.view(emb.shape[0], -1)\n",
    "#         for layer in layers:\n",
    "#             x = layer(x)\n",
    "#         logits = x # gives the count\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples = 1).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cd54abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suncyn.\n",
      "sunae.\n",
      "suno.\n",
      "sunceker.\n",
      "suncen.\n",
      "suna.\n",
      "sunnie.\n",
      "sunaira.\n",
      "sunta.\n",
      "sunneenar.\n",
      "sunce.\n",
      "sundrar.\n",
      "sunnie.\n",
      "sunsiyah.\n",
      "sunaleigh.\n",
      "suncema.\n",
      "sun.\n",
      "sunica.\n",
      "sunana.\n",
      "sundin.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "\n",
    "# asking model to predict names starting from 'sun'\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = [19, 21, 14]\n",
    "    context = [0] * block_size # contains index of each alpha initially '...'\n",
    "    context = context[1:] + [stoi['s']]\n",
    "    context = context[1:] + [stoi['u']]\n",
    "    context = context[1:] + [stoi['n']]\n",
    "    while True:\n",
    "        logits = model(torch.tensor([context]))\n",
    "#         emb = C[torch.tensor([context])] #(1, block_size, d)\n",
    "#         x = emb.view(emb.shape[0], -1)\n",
    "#         for layer in layers:\n",
    "#             x = layer(x)\n",
    "#         logits = x # gives the count\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples = 1).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "32e4314a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 21, 14)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['s'], stoi['u'], stoi['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9311d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
